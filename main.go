/*


Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package main

import (
	"context"
	"flag"
	"fmt"
	"os"
	"time"

	// Import all Kubernetes client auth plugins (e.g. Azure, GCP, OIDC, etc.)
	// to ensure that exec-entrypoint and run can make use of them.
	_ "k8s.io/client-go/plugin/pkg/client/auth"

	"github.com/darkowlzz/operator-toolkit/telemetry/export"
	"github.com/darkowlzz/operator-toolkit/webhook/cert"
	"go.uber.org/zap/zapcore"
	admissionregistrationv1 "k8s.io/api/admissionregistration/v1"
	"k8s.io/apimachinery/pkg/runtime"
	"k8s.io/apimachinery/pkg/types"
	clientgoscheme "k8s.io/client-go/kubernetes/scheme"
	_ "k8s.io/client-go/plugin/pkg/client/auth/gcp"
	ctrl "sigs.k8s.io/controller-runtime"
	"sigs.k8s.io/controller-runtime/pkg/client"
	"sigs.k8s.io/controller-runtime/pkg/log/zap"
	"sigs.k8s.io/controller-runtime/pkg/webhook"
	"sigs.k8s.io/controller-runtime/pkg/webhook/admission"

	nsdelete "github.com/storageos/api-manager/controllers/namespace-delete"
	nodedelete "github.com/storageos/api-manager/controllers/node-delete"
	nodelabel "github.com/storageos/api-manager/controllers/node-label"
	podmutator "github.com/storageos/api-manager/controllers/pod-mutator"
	"github.com/storageos/api-manager/controllers/pod-mutator/scheduler"
	pvclabel "github.com/storageos/api-manager/controllers/pvc-label"
	"github.com/storageos/api-manager/internal/controllers/sharedvolume"
	"github.com/storageos/api-manager/internal/pkg/cluster"
	"github.com/storageos/api-manager/internal/pkg/storageos"
	apimetrics "github.com/storageos/api-manager/internal/pkg/storageos/metrics"
	// +kubebuilder:scaffold:imports
)

const (
	// EventSourceName is added to Kubernetes events generated by the api
	// manager.  It can be used for filtering events.
	EventSourceName = "storageos-api-manager"
)

var (
	scheme   = runtime.NewScheme()
	setupLog = ctrl.Log.WithName("api-manager")
)

func init() {
	_ = clientgoscheme.AddToScheme(scheme)

	// +kubebuilder:scaffold:scheme
}

func main() {
	var loggerOpts zap.Options
	var namespace string
	var metricsAddr string
	var enableLeaderElection bool
	var schedulerName string
	var webhookServiceName string
	var webhookServiceNamespace string
	var webhookSecretName string
	var webhookSecretNamespace string
	var webhookConfigMutatingName string
	var webhookMutatePodsPath string
	var webhookCertRefreshInterval time.Duration
	var apiSecretPath string
	var apiEndpoint string
	var apiPollInterval time.Duration
	var apiRefreshInterval time.Duration
	var apiRetryInterval time.Duration
	var cacheExpiryInterval time.Duration
	var k8sCreatePollInterval time.Duration
	var k8sCreateWaitDuration time.Duration
	var gcNamespaceDeleteInterval time.Duration
	var gcNodeDeleteInterval time.Duration
	var resyncNodeLabelInterval time.Duration
	var resyncPVCLabelInterval time.Duration
	var gcNamespaceDeleteDelay time.Duration
	var gcNodeDeleteDelay time.Duration
	var resyncNodeLabelDelay time.Duration
	var resyncPVCLabelDelay time.Duration
	var nsDeleteWorkers int
	var nodeDeleteWorkers int
	var nodeLabelSyncWorkers int
	var pvcLabelSyncWorkers int
	flag.StringVar(&metricsAddr, "metrics-addr", ":8080", "The address the metric endpoint binds to.")
	flag.BoolVar(&enableLeaderElection, "enable-leader-election", false,
		"Enable leader election for controller manager. "+
			"Enabling this will ensure there is only one active controller manager.")
	flag.StringVar(&namespace, "namespace", "", "Namespace that the StorageOS components, including api-manager, are installed into.  Will be auto-detected if unset.")
	flag.StringVar(&schedulerName, "scheduler-name", "storageos-scheduler", "Name of the Pod scheduler to use for Pods with StorageOS volumes.  Set to an empty value to disable setting the Pod scheduler.")
	flag.StringVar(&webhookServiceName, "webhook-service-name", "storageos-webhook", "Name of the webhook service.")
	flag.StringVar(&webhookServiceNamespace, "webhook-service-namespace", "", "Namespace of the webhook service.  Will be auto-detected or value of -namespace if unset.")
	flag.StringVar(&webhookSecretName, "webhook-secret-name", "storageos-webhook", "Name of the webhook secret containing the certificate.")
	flag.StringVar(&webhookSecretNamespace, "webhook-secret-namespace", "", "Namespace of the webhook secret.  Will be auto-detected or value of -namespace if unset.")
	flag.StringVar(&webhookConfigMutatingName, "webhook-config-mutating", "storageos-mutating-webhook", "Name of the mutating webhook configuration.")
	flag.StringVar(&webhookMutatePodsPath, "webhook-mutate-pods-path", "/mutate-pods", "URL path of the Pod mutating webhook.")
	flag.DurationVar(&webhookCertRefreshInterval, "webhook-cert-refresh-interval", 30*time.Minute, "Frequency of webhook certificate refresh.")
	flag.StringVar(&apiSecretPath, "api-secret-path", "/etc/storageos/secrets/api", "Path where the StorageOS api secret is mounted.  The secret must have \"username\" and \"password\" set.")
	flag.StringVar(&apiEndpoint, "api-endpoint", "storageos", "The StorageOS api endpoint address.")
	flag.DurationVar(&apiPollInterval, "api-poll-interval", 5*time.Second, "Frequency of StorageOS api polling.")
	flag.DurationVar(&apiRefreshInterval, "api-refresh-interval", time.Minute, "Frequency of StorageOS api authentication token refresh.")
	flag.DurationVar(&apiRetryInterval, "api-retry-interval", 5*time.Second, "Frequency of StorageOS api retries on failure.")
	flag.DurationVar(&cacheExpiryInterval, "cache-expiry-interval", time.Minute, "Frequency of cached volume re-validation.")
	flag.DurationVar(&k8sCreatePollInterval, "k8s-create-poll-interval", 1*time.Second, "Frequency of Kubernetes api polling for new objects to appear once created.")
	flag.DurationVar(&k8sCreateWaitDuration, "k8s-create-wait-duration", 20*time.Second, "Maximum time to wait for new Kubernetes objects to appear.")
	flag.DurationVar(&gcNamespaceDeleteInterval, "namespace-delete-gc-interval", 1*time.Hour, "Frequency of namespace garbage collection.")
	flag.DurationVar(&gcNodeDeleteInterval, "node-delete-gc-interval", 1*time.Hour, "Frequency of node garbage collection.")
	flag.DurationVar(&resyncNodeLabelInterval, "node-label-resync-interval", 1*time.Hour, "Frequency of node label resync.")
	flag.DurationVar(&resyncPVCLabelInterval, "pvc-label-resync-interval", 1*time.Hour, "Frequency of PVC label resync.")
	flag.DurationVar(&gcNamespaceDeleteDelay, "namespace-delete-gc-delay", 20*time.Second, "Startup delay of initial namespace garbage collection.")
	flag.DurationVar(&gcNodeDeleteDelay, "node-delete-gc-delay", 30*time.Second, "Startup delay of initial node garbage collection.")
	flag.DurationVar(&resyncNodeLabelDelay, "node-label-resync-delay", 10*time.Second, "Startup delay of initial node label resync.")
	flag.DurationVar(&resyncPVCLabelDelay, "pvc-label-resync-delay", 5*time.Second, "Startup delay of initial PVC label resync.")
	flag.IntVar(&nodeDeleteWorkers, "node-delete-workers", 5, "Maximum concurrent node delete operations.")
	flag.IntVar(&nsDeleteWorkers, "namespace-delete-workers", 5, "Maximum concurrent namespace delete operations.")
	flag.IntVar(&nodeLabelSyncWorkers, "node-label-sync-workers", 5, "Maximum concurrent node label sync operations.")
	flag.IntVar(&pvcLabelSyncWorkers, "pvc-label-sync-workers", 5, "Maximum concurrent PVC label sync operations.")

	loggerOpts.BindFlags(flag.CommandLine)
	flag.Parse()

	f := func(ec *zapcore.EncoderConfig) {
		ec.TimeKey = "timestamp"
		ec.EncodeTime = zapcore.RFC3339NanoTimeEncoder
	}
	encoderOpts := func(o *zap.Options) {
		o.EncoderConfigOptions = append(o.EncoderConfigOptions, f)
	}
	ctrl.SetLogger(zap.New(zap.UseFlagOptions(&loggerOpts), zap.StacktraceLevel(zapcore.PanicLevel), encoderOpts))

	// Setup telemetry.
	telemetryShutdown, err := export.InstallJaegerExporter("api-manager")
	if err != nil {
		setupLog.Error(err, "unable to setup telemetry exporter")
		os.Exit(1)
	}
	defer telemetryShutdown()

	// Block startup until there is a working StorageOS API connection.  Unless
	// we loop here, we'll get a number of failures on cold cluster start as it
	// takes longer for the api to be ready than the api-manager to start.
	var api *storageos.Client
	for {
		username, password, err := storageos.ReadCredsFromMountedSecret(apiSecretPath)
		if err != nil {
			setupLog.Info(fmt.Sprintf("unable to read storageos api secret, retrying in %s", apiRetryInterval), "msg", err)
			apimetrics.Errors.Increment("setup", err)
			time.Sleep(apiRetryInterval)
			continue
		}
		api, err = storageos.NewTracedClient(username, password, apiEndpoint)
		if err == nil {
			apimetrics.Errors.Increment("setup", nil)
			break
		}
		setupLog.Info(fmt.Sprintf("unable to connect to storageos api, retrying in %s", apiRetryInterval), "msg", err)
		apimetrics.Errors.Increment("setup", err)
		time.Sleep(apiRetryInterval)
	}
	setupLog.Info("connected to the storageos api", "api-endpoint", apiEndpoint)

	// Only attempt to grab leader lock once we have an API connection.
	mgr, err := ctrl.NewManager(ctrl.GetConfigOrDie(), ctrl.Options{
		Scheme:             scheme,
		MetricsBindAddress: metricsAddr,
		Port:               9443,
		LeaderElection:     enableLeaderElection,
		LeaderElectionID:   "d73494fd.storageos.com",
	})
	if err != nil {
		setupLog.Error(err, "unable to start manager")
		os.Exit(1)
	}

	// Create an uncached client to be used in the certificate manager.
	// NOTE: Cached client from manager can't be used here because the cache is
	// uninitialized at this point.
	cli, err := client.New(mgr.GetConfig(), client.Options{Scheme: mgr.GetScheme()})
	if err != nil {
		setupLog.Error(err, "failed to create raw client")
		os.Exit(1)
	}

	// Get the namespace that we're running in.  This will always be set in
	// normal deployments, but allow it to be set manually for testing.
	if namespace == "" {
		namespace, err = cluster.Namespace()
		if err != nil {
			setupLog.Error(err, "unable to determine namespace, set --namespace.")
		}
	}

	// The webhook secret and service should always be in the same namespace as
	// the api-manager.
	if webhookSecretNamespace == "" {
		webhookSecretNamespace = namespace
	}
	if webhookServiceNamespace == "" {
		webhookServiceNamespace = namespace
	}

	// Configure the certificate manager.
	certOpts := cert.Options{
		CertRefreshInterval: webhookCertRefreshInterval,
		Service: &admissionregistrationv1.ServiceReference{
			Name:      webhookServiceName,
			Namespace: webhookServiceNamespace,
		},
		Client:                    cli,
		SecretRef:                 &types.NamespacedName{Name: webhookSecretName, Namespace: webhookSecretNamespace},
		MutatingWebhookConfigRefs: []types.NamespacedName{{Name: webhookConfigMutatingName}},
	}
	// Create certificate manager without manager to start the provisioning
	// immediately.
	// NOTE: Certificate Manager implements nonLeaderElectionRunnable interface
	// but since the webhook server is also a nonLeaderElectionRunnable, they
	// start at the same time, resulting in a race condition where sometimes
	// the certificates aren't available when the webhook server starts. By
	// passing nil instead of the manager, the certificate manager is not
	// managed by the controller manager. It starts immediately, in a blocking
	// fashion, ensuring that the cert is created before the webhook server
	// starts.
	if err := cert.NewManager(nil, certOpts); err != nil {
		setupLog.Error(err, "unable to provision certificate")
		os.Exit(1)
	}

	// +kubebuilder:scaffold:builder

	// Events sent on apiReset channel will trigger the api client to re-initialise.
	apiReset := make(chan struct{})

	// Parent context will be closed on interrupt or sigterm.
	ctx, cancel := context.WithCancel(ctrl.SetupSignalHandler())
	defer cancel()

	// Goroutine to handle api credential refreshes and client reconnects
	// whenever events are received on the apiReset channel.
	go func() {
		err := api.Refresh(ctx, apiSecretPath, apiReset, apiRefreshInterval, apimetrics.Errors, setupLog)
		setupLog.Info("api token refresh stopped", "reason", err)
		os.Exit(1)
	}()

	// Register controllers with controller manager.
	setupLog.Info("starting shared volume controller ")
	if err := sharedvolume.NewReconciler(api, apiReset, mgr.GetClient(), apiPollInterval, cacheExpiryInterval, k8sCreatePollInterval, k8sCreateWaitDuration, mgr.GetEventRecorderFor(EventSourceName)).SetupWithManager(mgr); err != nil {
		setupLog.Error(err, "failed to register shared volume reconciler")
		os.Exit(1)
	}

	setupLog.Info("starting PVC label sync controller ")
	if err := pvclabel.NewReconciler(api, mgr.GetClient(), resyncPVCLabelDelay, resyncPVCLabelInterval).SetupWithManager(mgr, pvcLabelSyncWorkers); err != nil {
		setupLog.Error(err, "failed to register pvc label reconciler")
		os.Exit(1)
	}
	setupLog.Info("starting node label sync controller ")
	if err := nodelabel.NewReconciler(api, mgr.GetClient(), resyncNodeLabelDelay, resyncNodeLabelInterval).SetupWithManager(mgr, nodeLabelSyncWorkers); err != nil {
		setupLog.Error(err, "failed to register node label reconciler")
		os.Exit(1)
	}
	setupLog.Info("starting node delete controller ")
	if err := nodedelete.NewReconciler(api, mgr.GetClient(), gcNodeDeleteDelay, gcNodeDeleteInterval).SetupWithManager(mgr, nodeDeleteWorkers); err != nil {
		setupLog.Error(err, "failed to register node delete reconciler")
		os.Exit(1)
	}
	setupLog.Info("starting namespace delete controller ")
	if err := nsdelete.NewReconciler(api, mgr.GetClient(), gcNamespaceDeleteDelay, gcNamespaceDeleteInterval).SetupWithManager(mgr, nsDeleteWorkers); err != nil {
		setupLog.Error(err, "failed to register namespace delete reconciler")
		os.Exit(1)
	}

	// Register webhook controllers.
	decoder, err := admission.NewDecoder(scheme)
	if err != nil {
		setupLog.Error(err, "failed to build decoder")
		os.Exit(1)
	}

	podMutator := podmutator.NewController(mgr.GetClient(), decoder, []podmutator.Mutator{
		scheduler.NewPodSchedulerSetter(mgr.GetClient(), schedulerName),
	})
	mgr.GetWebhookServer().Register(webhookMutatePodsPath, &webhook.Admission{Handler: podMutator})

	setupLog.Info("starting manager")
	if err := mgr.Start(ctx); err != nil {
		setupLog.Error(err, "failed to start manager")
		os.Exit(1)
	}
	setupLog.Info("shutdown complete")
}
